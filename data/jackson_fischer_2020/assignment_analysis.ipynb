{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3121f78-4645-4abc-9beb-e5f33a818993",
   "metadata": {},
   "source": [
    "# Assignment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7725d8-7052-4dfa-9558-5a77dc86742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m pip install numpy pandas simutome spellmatch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea949815-ec30-4ce4-960a-44170939040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simutome import Simutome\n",
    "from spellmatch.matching.algorithms.spellmatch import Spellmatch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "rng = np.random.default_rng(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed2150-bb9b-41f4-b1b8-689948c1c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_points_dir = \"source_points\"\n",
    "source_clusters_dir = \"source_clusters\"\n",
    "source_intensities_dir = \"source_intensities\"\n",
    "\n",
    "simutome_kwargs = {\n",
    "    # see ../kuett_catena_2022/parameters.ipynb\n",
    "    \"exclude_cells\": True,\n",
    "    \"cell_diameter_mean\": 7.931,\n",
    "    \"cell_diameter_std\": 1.768,\n",
    "}\n",
    "\n",
    "section_thicknesses = [2.0, 4.0, 6.0, 8.0, 10.0]\n",
    "\n",
    "spellmatch_kwargs = {\n",
    "    \"intensity_transform\": np.arcsinh,\n",
    "    \"scores_tol\": 1e-6,\n",
    "    \"filter_outliers\": False,\n",
    "    \"adj_radius\": 15,\n",
    "    \"alpha\": 0.8,\n",
    "    \"intensity_weight\": 1.0,\n",
    "    \"intensity_interp_lmd\": 1.0,\n",
    "    \"shared_intensity_pca_n_components\": 10,\n",
    "    \"spatial_cdist_prior_thres\": 25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06c902-f510-41ce-b1cd-ee7e7e80f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_points_files = sorted(Path(source_points_dir).glob(\"*.csv\"))\n",
    "source_clusters_files = sorted(Path(source_clusters_dir).glob(\"*.csv\"))\n",
    "source_intensities_files = sorted(Path(source_intensities_dir).glob(\"*.csv\"))\n",
    "assert len(source_points_files) == len(source_clusters_files) == len(source_intensities_files)\n",
    "\n",
    "simutome = Simutome(**simutome_kwargs, seed=rng)\n",
    "spellmatch = Spellmatch(**spellmatch_kwargs)\n",
    "\n",
    "assignment_analysis_dir = Path(\"assignment_analysis\")\n",
    "scores_dir = assignment_analysis_dir / \"scores\"\n",
    "assignment_analysis_dir.mkdir(exist_ok=True)\n",
    "scores_dir.mkdir(exist_ok=True)\n",
    "\n",
    "results = []\n",
    "pbar = tqdm(total=len(section_thicknesses) * len(source_points_files))\n",
    "for section_thickness in section_thicknesses:\n",
    "    for source_points_file, source_clusters_file, source_intensities_file in zip(\n",
    "        source_points_files, source_clusters_files, source_intensities_files\n",
    "    ):\n",
    "        source_points = pd.read_csv(source_points_file, index_col=\"cell\")\n",
    "        source_clusters = pd.read_csv(source_clusters_file, index_col=\"cell\")\n",
    "        source_intensities = pd.read_csv(source_intensities_file, index_col=\"cell\")\n",
    "        cell_indices, cell_coords, cell_intensities = simutome.generate_section(\n",
    "            source_points.to_numpy(),\n",
    "            section_thickness,\n",
    "            cell_intensities=source_intensities.loc[source_points.index, :].to_numpy(),\n",
    "            cell_clusters=source_clusters.loc[source_points.index, :].iloc[:, 0].to_numpy(),\n",
    "        )\n",
    "        target_points = pd.DataFrame(\n",
    "            cell_coords,\n",
    "            index=source_points.index[cell_indices],\n",
    "            columns=source_points.columns,\n",
    "        )\n",
    "        target_intensities = pd.DataFrame(\n",
    "            cell_intensities,\n",
    "            index=source_intensities.index[cell_indices],\n",
    "            columns=source_intensities.columns,\n",
    "        )\n",
    "        scores = spellmatch.match_points(\n",
    "                source_points_file.name,\n",
    "                \"simutome\",\n",
    "                source_points,\n",
    "                target_points,\n",
    "                source_intensities=source_intensities,\n",
    "                target_intensities=target_intensities,\n",
    "        )\n",
    "        scores_file_name = f\"scores_{section_thickness:04.1f}_{source_points_file.stem}.nc\"\n",
    "        scores.to_netcdf(path=scores_dir / scores_file_name)\n",
    "        results.append(\n",
    "            {\n",
    "                \"section_thickness\": section_thickness,\n",
    "                \"source_points_file\": source_points_file.name,\n",
    "                \"source_clusters_file\": source_clusters_file.name,\n",
    "                \"source_intensities_file\": source_intensities_file.name,\n",
    "                \"scores_file\": scores_file_name,\n",
    "            },\n",
    "        )\n",
    "        pbar.update()\n",
    "pbar.close()\n",
    "results = pd.DataFrame(data=results)\n",
    "results.to_csv(assignment_analysis_dir / \"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
